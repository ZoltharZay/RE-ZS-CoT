DATASETS_DIRECTORY = 'datasets'
API_MAX_RETRIES = 3
API_MAX_TIMEOUT = 120
RANDOM_SEED = 42
NUM_FEW_SHOT_SAMPLES = 10


gpt_four_1 = "gpt-4.1-2025-04-14"
gpt_four_1_mini = "gpt-4.1-mini-2025-04-14"
gpt_four_1_nano = "gpt-4.1-nano-2025-04-14"
gpt_four_o = "gpt-4o-2024-08-06"
gpt_four_o_mini = "gpt-4o-mini-2024-07-18"
llama_three_three_instruct_SEVENTY_MODEL= "llama-3.3-70b-instruct"

#12-14b
phi_4_14b = "phi4:14b-q4_K_M"
mistral_nemo_12b = "mistral-nemo:12b-instruct-2407-q4_K_M"
qwen_2_5_14b= "qwen2.5:14b-instruct-q4_K_M"
gemma_3_12b = "gemma3:12b-it-q4_K_M"
    


#2-3b
granite_3_2_2b = "granite3.2:2b-instruct-q4_K_M"
llama_3_2_3b = "llama3.2:3b-instruct-q4_K_M"
qwen_2_5_3b = "qwen2.5:3b-instruct-q4_K_M"
gemma_2_2b = "gemma2:2b-instruct-q4_K_M"
phi_4_mini_3b = "phi4-mini:3.8b-q4_K_M"
granite_3_3_2b = "granite3.3:2b"

#7-9b
granite_3_2_8b = "granite3.2:8b-instruct-q4_K_M"
granite_3_3_8b = "granite3.3:8b"
llama_3_1_8b = "llama3.1:8b-instruct-q4_K_M"
mistral_7b = "mistral:7b-instruct-q4_K_M"
qwen_2_5_7b = "qwen2.5:7b-instruct-q4_K_M"
gemma_2_9b = "gemma2:9b-instruct-q4_K_M"

